{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d77b0",
   "metadata": {},
   "source": [
    "#Â Multi Layer Percepron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941630",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b340ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e5997",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "The **multi layer perceptron (MLP)** is feedforward neural network composed of successive layers (cf. Figure below).\n",
    "\n",
    "<img src=\"files/figures/MLP.jpg\" width=\"600px\"/>\n",
    " \n",
    "The dynamics of an MLP is given by the following equations (sample and batch versions):\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\textbf{sample $\\boldsymbol{x}$} & \\textbf{batch $\\boldsymbol{X_i}$} \\\\\n",
    "\\begin{cases}\n",
    "\\boldsymbol{a^{[0]}} ~=~ \\boldsymbol{x} & \\\\\n",
    "\\boldsymbol{z^{[l]}} ~=~ \\boldsymbol{W^{[l]}} \\boldsymbol{a^{[l-1]}} + \\boldsymbol{b^{[l]}}, & l = 1, \\dots, L \\\\\n",
    "\\boldsymbol{a^{[l]}} ~=~ \\boldsymbol{\\sigma} \\left( \\boldsymbol{z^{[l]}} \\right), & l = 1, \\dots, L\n",
    "\\end{cases}\n",
    "~&~\n",
    "\\begin{cases}\n",
    "\\boldsymbol{A^{[0]}} ~=~ \\boldsymbol{X_i}\t\\\\\n",
    "\\boldsymbol{Z^{[l]}} ~=~ \\boldsymbol{W^{[l]}} \\boldsymbol{A^{[l-1]}} \\oplus \\boldsymbol{b^{[l]}}, & l = 1, \\dots, L \\\\\n",
    "\\boldsymbol{A^{[l]}} ~=~ \\boldsymbol{\\sigma} \\big( \\boldsymbol{Z^{[l]}} \\big), & l = 1, \\dots, L\n",
    "\\end{cases}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab415f92",
   "metadata": {},
   "source": [
    "- Define a class `MLP()` which takes a list `[n1, n2, ..., nL]` as parameter and creates an MLP with $L$ layers of $n_i$ neurons each, for $i= 1, \\dots, L$.\n",
    "- Initializes the weights matrices $\\boldsymbol{W^{[l]}}$ and the bias vectors $\\boldsymbol{b^{[l]}}$ randomly from a normal distribution $\\mathcal{N}(0, 1)$ (`torch.normal()`).\n",
    "- The first layer is the input layer and thus has no biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875d440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09ebbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8923a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8ed07c5",
   "metadata": {},
   "source": [
    "- Add a method `forward(X)` which takes a batch of vectors `X` as inputs (2D tensor), and computes the forward pass of the network on this batch.\n",
    "- For the activation function $\\sigma$, take the `tanh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbca33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45d9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1edac4cd",
   "metadata": {},
   "source": [
    "## Application to the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293f4a4",
   "metadata": {},
   "source": [
    "The **MNIST dataset** consists of handwritten digits. The MNIST classification problem consists in predicting the correct digit represented on an image.\n",
    "\n",
    "<img src=\"files/figures/mnist.png\" width=\"600px\"/>\n",
    "\n",
    "- Load the train and test MNIST datasets using the following commands:\n",
    "```\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "```\n",
    "Each sample consists of a tensor (the image encoded in black and white), and a label (the digit that it represents).\n",
    "- Examine the train and test sets.\n",
    "- Visualize some data samples (tensors) using `plt.imshow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d9954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c67332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eea3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d85e3f",
   "metadata": {},
   "source": [
    "Each sample is a $28 \\times 28$ 2D-tensor representing a handwritten digit. Note that the sample can be \"flattened\"  into a $28 \\cdot 28 = 784$ 1D-vector using the method `flatten()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f5fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d0c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ea637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b5b9e2",
   "metadata": {},
   "source": [
    "A **dataloader** creates batches of samples from a dataset so that they can be passed into a model.\n",
    "- Create a train and test dataloader using the following commands:\n",
    "```\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "```\n",
    "- Note that dataloaders are not subscriptable.\n",
    "- Try to catch one batch of the dataloader and examine it.\n",
    "- Write a function that reshapes a batch of size $64 \\times 1 \\times 28 \\times 28$ into a tensor of size $784 \\times 64$.<br>\n",
    "(use `torch.squeeze()`, `torch.reshape()`, `torch.flatten()`, `torch.transpose()`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e892af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9cbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fe14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4bbb26e",
   "metadata": {},
   "source": [
    "- Instantiate a 4-layer MLP with the following characteristics:\n",
    "    - Layer 1 (or input layer): size 784\n",
    "    - Layer 2: size 128\n",
    "    - Layer 3: size 128\n",
    "    - Layer 4 (or output layer): size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991415bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b41de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c3b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a28a679d",
   "metadata": {},
   "source": [
    "- Pass all train samples through your network batch by batch:<br>\n",
    "Create a function `process_data(dataloader, network)` that performs this.\n",
    "- Gather all the outputs into 1 tensor.\n",
    "- Take the argmax of the outputs to obtain the predictions.\n",
    "- Get the classification report associated to your predictions and real labels:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "- What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23bc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded867c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6265d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "186f4207",
   "metadata": {},
   "source": [
    "**Oviously, the network is untrained, and thus does not preforms better than chance (10%)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58043b",
   "metadata": {},
   "source": [
    "## Train the MLP via Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c4c94",
   "metadata": {},
   "source": [
    "- Update the **weights of the last layer** only so that they correspond to the solution of a **Ridge regression**.<br>\n",
    "https://en.wikipedia.org/wiki/Ridge_regression<br>\n",
    "\n",
    "More precisely:\n",
    "- Pass the train set through the network and get the predictions of the penultimate layer<br>\n",
    "(add a method `forward_penultimate()` in the class `MLP`)\n",
    "- Compute the closed-form solution of the Ridge regression:\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\widehat {\\beta }}_{\\text{ridge}}=(X^{T}X+kI_{p})^{-1}X^{T}y}\n",
    "$$\n",
    "\n",
    "where\n",
    "- $X$ is the <span style=\"color:blue\">row-wise concatenation</span> of the penultimate outputs $\\boldsymbol{a_i}^{[L-1]}$, for $i = 1, \\dots, N$;\n",
    "- $I_{p}$ is the identity matrix of dim $p$;\n",
    "- $k > 0$ is a regularization parameter (e.g. $0.1$);\n",
    "- $y$ is the <span style=\"color:blue\">row-wise concatenation</span> of the 1-hot encoded targets $\\boldsymbol{y_i}$, for $i = 1, \\dots, N$ (`torch.nn.functional.one_hot()`).\n",
    "- **Set weights of the last layer $\\boldsymbol{W}^{[L]}$ as the solution of the Ridge regression.**\n",
    "- **Set the bias of the last layer $\\boldsymbol{b}^{[L]}$ to $\\boldsymbol{0}$.**\n",
    "- Recompute the predictions associated to the train and test sets.\n",
    "- Compute the classification reports.\n",
    "- What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cd267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ed21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948d335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed6d1106",
   "metadata": {},
   "source": [
    "**The results have drastically improved!**\n",
    "- Note that $\\boldsymbol{W}^{[1]}, \\boldsymbol{W}^{[2]}$ are kept untrained (randomly initialized).\n",
    "- Only $\\boldsymbol{W}^{[3]}$ is trained via by a **Ridge regression**.\n",
    "- This suffices to drastically improve the results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
